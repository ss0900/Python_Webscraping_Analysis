{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b9a6f0",
   "metadata": {},
   "source": [
    "2-1. Nate 뉴스기사 제목 스크래핑하기\n",
    "\n",
    "https://news.nate.com/recent?mid=n0100\n",
    "최신뉴스, 정치 , 경제, 사회, 세계, IT/과학\n",
    "6개의 섹션의 뉴스를 출력하는 함수를 생성하여 스크래핑하기\n",
    "\n",
    "Image, 기사제목, 기사링크\n",
    "\n",
    "뉴스기사의 Image를 출력하세요.\n",
    "\n",
    "1) Image의 도메인이름이 포함된 경로와 src 속성의 경로를 합치려면 urljoin 함수를 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "url = 'https://news.nate.com/recent?mid=n0100'\n",
    "src='//thumbnews.nateimg.co.kr/news90///news.nateimg.co.kr/orgImg/na/2025/07/23/7408335_high.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba21b49",
   "metadata": {},
   "source": [
    "2) Image 출력은 Image 클래스와 display 함수를 사용하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9178452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833102d",
   "metadata": {},
   "source": [
    "3) img 엘리먼트의 존재 여부를 체크하신 후에 src 속성의 이미지를 경로를 추출하기\n",
    "=> Image가 없는 뉴스도 있기 때문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89dc06f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 최신뉴스 ---\n",
      "No articles found for 최신뉴스. Check the CSS selector.\n",
      "--- 정치 ---\n",
      "No articles found for 정치. Check the CSS selector.\n",
      "--- 경제 ---\n",
      "No articles found for 경제. Check the CSS selector.\n",
      "--- 사회 ---\n",
      "No articles found for 사회. Check the CSS selector.\n",
      "--- 세계 ---\n",
      "No articles found for 세계. Check the CSS selector.\n",
      "--- IT/과학 ---\n",
      "No articles found for IT/과학. Check the CSS selector.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def scrape_nate_news(section_name, url):\n",
    "    \"\"\"\n",
    "    Scrapes news articles from a given Nate News section URL,\n",
    "    extracts image, title, and link, and displays the image.\n",
    "\n",
    "    Args:\n",
    "        section_name (str): The name of the news section (e.g., \"최신뉴스\").\n",
    "        url (str): The URL of the news section.\n",
    "    \"\"\"\n",
    "    print(f\"--- {section_name} ---\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all list items containing news articles\n",
    "        articles = soup.select('.newsContents .clear') # Or other appropriate selector if needed\n",
    "\n",
    "        if not articles:\n",
    "            print(f\"No articles found for {section_name}. Check the CSS selector.\")\n",
    "            return\n",
    "\n",
    "        for article in articles:\n",
    "            # Extract image\n",
    "            img_tag = article.select_one('img')\n",
    "            if img_tag and img_tag.has_attr('src'):\n",
    "                img_src = img_tag['src']\n",
    "                # Construct full image URL using urljoin\n",
    "                full_img_url = urljoin(url, img_src)\n",
    "                print(f\"Image URL: {full_img_url}\")\n",
    "                try:\n",
    "                    display(Image(url=full_img_url))\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not display image from {full_img_url}: {e}\")\n",
    "            else:\n",
    "                print(\"No image found for this article.\")\n",
    "\n",
    "            # Extract title and link\n",
    "            title_tag = article.select_one('.tb .tit') # Assuming the title is within a .tb element and has a .tit class\n",
    "            if title_tag:\n",
    "                link_tag = title_tag.select_one('a')\n",
    "                if link_tag and link_tag.has_attr('href'):\n",
    "                    title = link_tag.get_text(strip=True)\n",
    "                    link = urljoin(url, link_tag['href']) # Use urljoin for relative links\n",
    "                    print(f\"Title: {title}\")\n",
    "                    print(f\"Link: {link}\\n\")\n",
    "                else:\n",
    "                    print(\"No link found for this title.\")\n",
    "            else:\n",
    "                print(\"No title found for this article.\\n\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {section_name} from {url}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred for {section_name}: {e}\")\n",
    "\n",
    "# URLs for the different Nate News sections\n",
    "nate_news_sections = {\n",
    "    \"최신뉴스\": \"https://news.nate.com/recent?mid=n0100\",\n",
    "    \"정치\": \"https://news.nate.com/politics?mid=n1001\",\n",
    "    \"경제\": \"https://news.nate.com/economy?mid=n1002\",\n",
    "    \"사회\": \"https://news.nate.com/society?mid=n1003\",\n",
    "    \"세계\": \"https://news.nate.com/world?mid=n1004\",\n",
    "    \"IT/과학\": \"https://news.nate.com/it?mid=n1005\"\n",
    "}\n",
    "\n",
    "# Scrape each section\n",
    "for section_name, url in nate_news_sections.items():\n",
    "    scrape_nate_news(section_name, url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3b9be",
   "metadata": {},
   "source": [
    "2-2. 하나의 네이버 웹툰과 1개의 회차에 대한 Image 다운로드 하기\n",
    ":  하나의 웹툰의 제목(title)과 회차번호(no),회차의URL(url) 을 입력으로 받는 함수를 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8ccc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_one_episode(title,no,url):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2384e",
   "metadata": {},
   "source": [
    "아래와 같이 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a8c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_one_episode('일렉시드',341,'https://comic.naver.com/webtoon/detail?titleId=717481&no=341&week=wed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e90a6e7",
   "metadata": {},
   "source": [
    "img\\일렉시드\\341 디렉토리가 생성되며, 그 디렉토리 아래에 웹툰 image들이 다운로드 되도록 해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5db3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운로드 경로: img\\일렉시드\\341\n",
      "이미지 다운로드 완료: 001.jpg\n",
      "이미지 다운로드 완료: 002.jpg\n",
      "이미지 다운로드 완료: 003.jpg\n",
      "이미지 다운로드 완료: 004.jpg\n",
      "이미지 다운로드 완료: 005.jpg\n",
      "이미지 다운로드 완료: 006.jpg\n",
      "이미지 다운로드 완료: 007.jpg\n",
      "이미지 다운로드 완료: 008.jpg\n",
      "이미지 다운로드 완료: 009.jpg\n",
      "이미지 다운로드 완료: 010.jpg\n",
      "이미지 다운로드 완료: 011.jpg\n",
      "이미지 다운로드 완료: 012.jpg\n",
      "이미지 다운로드 완료: 013.jpg\n",
      "이미지 다운로드 완료: 014.jpg\n",
      "이미지 다운로드 완료: 015.jpg\n",
      "이미지 다운로드 완료: 016.jpg\n",
      "이미지 다운로드 완료: 017.jpg\n",
      "이미지 다운로드 완료: 018.jpg\n",
      "이미지 다운로드 완료: 019.jpg\n",
      "이미지 다운로드 완료: 020.jpg\n",
      "이미지 다운로드 완료: 021.jpg\n",
      "이미지 다운로드 완료: 022.jpg\n",
      "이미지 다운로드 완료: 023.jpg\n",
      "이미지 다운로드 완료: 024.jpg\n",
      "이미지 다운로드 완료: 025.jpg\n",
      "이미지 다운로드 완료: 026.jpg\n",
      "이미지 다운로드 완료: 027.jpg\n",
      "이미지 다운로드 완료: 028.jpg\n",
      "이미지 다운로드 완료: 029.jpg\n",
      "이미지 다운로드 완료: 030.jpg\n",
      "이미지 다운로드 완료: 031.jpg\n",
      "이미지 다운로드 완료: 032.jpg\n",
      "이미지 다운로드 완료: 033.jpg\n",
      "이미지 다운로드 완료: 034.jpg\n",
      "이미지 다운로드 완료: 035.jpg\n",
      "이미지 다운로드 완료: 036.jpg\n",
      "이미지 다운로드 완료: 037.jpg\n",
      "이미지 다운로드 완료: 038.jpg\n",
      "이미지 다운로드 완료: 039.jpg\n",
      "이미지 다운로드 완료: 040.jpg\n",
      "이미지 다운로드 완료: 041.jpg\n",
      "이미지 다운로드 완료: 042.jpg\n",
      "이미지 다운로드 완료: 043.jpg\n",
      "이미지 다운로드 완료: 044.jpg\n",
      "이미지 다운로드 완료: 045.jpg\n",
      "이미지 다운로드 완료: 046.jpg\n",
      "이미지 다운로드 완료: 047.jpg\n",
      "이미지 다운로드 완료: 048.jpg\n",
      "이미지 다운로드 완료: 049.jpg\n",
      "이미지 다운로드 완료: 050.jpg\n",
      "이미지 다운로드 완료: 051.jpg\n",
      "이미지 다운로드 완료: 052.jpg\n",
      "이미지 다운로드 완료: 053.jpg\n",
      "이미지 다운로드 완료: 054.jpg\n",
      "이미지 다운로드 완료: 055.jpg\n",
      "이미지 다운로드 완료: 056.jpg\n",
      "이미지 다운로드 완료: 057.jpg\n",
      "이미지 다운로드 완료: 058.jpg\n",
      "이미지 다운로드 완료: 059.jpg\n",
      "이미지 다운로드 완료: 060.jpg\n",
      "이미지 다운로드 완료: 061.jpg\n",
      "이미지 다운로드 완료: 062.jpg\n",
      "이미지 다운로드 완료: 063.jpg\n",
      "이미지 다운로드 완료: 064.jpg\n",
      "이미지 다운로드 완료: 065.jpg\n",
      "이미지 다운로드 완료: 066.jpg\n",
      "이미지 다운로드 완료: 067.jpg\n",
      "이미지 다운로드 완료: 068.jpg\n",
      "이미지 다운로드 완료: 069.jpg\n",
      "이미지 다운로드 완료: 070.jpg\n",
      "이미지 다운로드 완료: 071.jpg\n",
      "이미지 다운로드 완료: 072.jpg\n",
      "이미지 다운로드 완료: 073.jpg\n",
      "이미지 다운로드 완료: 074.jpg\n",
      "이미지 다운로드 완료: 075.jpg\n",
      "이미지 다운로드 완료: 076.jpg\n",
      "이미지 다운로드 완료: 077.jpg\n",
      "이미지 다운로드 완료: 078.jpg\n",
      "이미지 다운로드 완료: 079.jpg\n",
      "이미지 다운로드 완료: 080.jpg\n",
      "이미지 다운로드 완료: 081.jpg\n",
      "이미지 다운로드 완료: 082.jpg\n",
      "이미지 다운로드 완료: 083.jpg\n",
      "이미지 다운로드 완료: 084.jpg\n",
      "이미지 다운로드 완료: 085.jpg\n",
      "이미지 다운로드 완료: 086.jpg\n",
      "이미지 다운로드 완료: 087.jpg\n",
      "이미지 다운로드 완료: 088.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_one_episode(title, no, url):\n",
    "    \"\"\"\n",
    "    네이버 웹툰의 특정 회차 이미지를 다운로드합니다.\n",
    "\n",
    "    Args:\n",
    "        title (str): 웹툰의 제목.\n",
    "        no (int): 회차 번호.\n",
    "        url (str): 해당 회차의 URL.\n",
    "    \"\"\"\n",
    "    # 다운로드 경로 설정: img/웹툰제목/회차번호\n",
    "    download_dir = os.path.join(\"img\", title, str(no))\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    print(f\"다운로드 경로: {download_dir}\")\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # HTTP 오류 발생 시 예외 발생\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"URL 요청 중 오류 발생: {e}\")\n",
    "        return\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # 웹툰 이미지를 포함하는 div 태그 찾기 (클래스 이름이 'wt_viewer'인 div)\n",
    "    viewer_div = soup.find('div', class_='wt_viewer')\n",
    "\n",
    "    if not viewer_div:\n",
    "        print(\"웹툰 이미지를 찾을 수 없습니다. HTML 구조가 변경되었을 수 있습니다.\")\n",
    "        return\n",
    "\n",
    "    # viewer_div 내의 모든 이미지 태그 찾기\n",
    "    images = viewer_div.find_all('img')\n",
    "\n",
    "    if not images:\n",
    "        print(\"다운로드할 이미지가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        img_url = img.get('src')\n",
    "        if img_url and img_url.startswith(('http://', 'https://')):\n",
    "            try:\n",
    "                img_data = requests.get(img_url).content\n",
    "                img_name = f\"{i+1:03d}.jpg\"  # 이미지 파일명 (예: 001.jpg, 002.jpg)\n",
    "                img_path = os.path.join(download_dir, img_name)\n",
    "                with open(img_path, 'wb') as f:\n",
    "                    f.write(img_data)\n",
    "                print(f\"이미지 다운로드 완료: {img_name}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"이미지 다운로드 중 오류 발생 ({img_url}): {e}\")\n",
    "        else:\n",
    "            print(f\"유효하지 않은 이미지 URL: {img_url}\")\n",
    "\n",
    "# 함수 호출 예시\n",
    "download_one_episode('일렉시드', 341, 'https://comic.naver.com/webtoon/detail?titleId=717481&no=341&week=wed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e11bb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
